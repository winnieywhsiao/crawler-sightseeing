{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Run Time： 3.5843710899353027\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import requests\n",
    "import time\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pymysql\n",
    "import re\n",
    "from lxml import html\n",
    "\n",
    "#取得餐廳資訊\n",
    "def getResta(url):\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    print(url)\n",
    "                         \n",
    "    # name\n",
    "    try:\n",
    "        global name\n",
    "        for ele in soup.select('h1.restaurants-detail-top-info-TopInfo__restaurantName--1IKBe'):\n",
    "            name = ele.text\n",
    "                         \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    # city_name\n",
    "    try:\n",
    "        p = requests.get(url)\n",
    "        tree = html.fromstring(p.content)\n",
    "        cn = tree.xpath('//*[@id=\"taplc_trip_planner_breadcrumbs_0\"]/ul/li[3]/a/span/text()')\n",
    "        for i in range(len(cn)):\n",
    "            c_name = cn[i]\n",
    "                         \n",
    "    except AttributrError:\n",
    "        c_name = \"None\"\n",
    "                         \n",
    "    # address\n",
    "    try:\n",
    "        global address\n",
    "        for i in soup.select('span.restaurants-detail-overview-cards-LocationOverviewCard__detailLinkText--co3ei'):\n",
    "            address = i.text\n",
    "                         \n",
    "    except AttributeError:\n",
    "        address = \"None\"\n",
    "                         \n",
    "    # rate\n",
    "    try:\n",
    "        score = soup.find('div', 'ratingContainer')\n",
    "        rate = score.span['alt']\n",
    "        Rate = re.findall(r'[\\d\\.\\d]+', rate)\n",
    "        rate = Rate[0]\n",
    "                         \n",
    "    except AttributeError:\n",
    "        rate = 0\n",
    "                         \n",
    "    # comment\n",
    "    try:\n",
    "        comment = soup.find('span', 'reviewCount')\n",
    "        c_comment = comment.get_text()\n",
    "        Com = re.findall(r'[\\d\\,\\d]+', c_comment)\n",
    "        c_comment = int(Com[0].replace(\",\", \"\"))\n",
    "                         \n",
    "    except AttributeError:\n",
    "        c_comment = 0\n",
    "                         \n",
    "    new_id = get_newID()\n",
    "    href = url\n",
    "    data_type = \"restaurant\"\n",
    "    color = \"purple\"\n",
    "    shape = \"circle\"\n",
    "    # id,name,city,address,type,comment,rate,href,color,shape\n",
    "    add_Data(new_id, name, c_name, address,\n",
    "             data_type, c_comment, rate, href, color, shape)\n",
    "    \n",
    "    print(\"餐廳名：\" + name)\n",
    "print(\"=\"*100)\n",
    "\n",
    "\n",
    "def get_newID():\n",
    "    last_id = \"\"\n",
    "    resta_id = \"SELECT MAX(id) FROM resta_data\"\n",
    "    cur.execute(resta_id)\n",
    "    for id in cur:\n",
    "        num = re.findall(r'[\\d\\.\\d]+', id[0])\n",
    "        num = int(num[0]) + 1\n",
    "        last_id = 'R{0:04}'.format(num)\n",
    "    return last_id\n",
    "\n",
    "#加入site資料到資料庫\n",
    "def add_Data(id, name, city_name, address, type, c_cmt, rate, href, color, shape):\n",
    "    add_data = (\"INSERT INTO resta_data\"\n",
    "                \"(id,name,city_name,address,type,comment,rate,href,color,shape) \"\n",
    "                \"VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\")\n",
    "    data = (id, name, city_name, address, type, c_cmt, rate, href, color, shape)\n",
    "    cur.execute(add_data, data)\n",
    "    # cnx.commit()\n",
    "\n",
    "\n",
    "#Main\n",
    "tStart = time.time()\n",
    "# driver = webdriver.Chrome(\"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe\")\n",
    "\n",
    "\n",
    "cnx = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    passwd=\"12345\",\n",
    "    database='test'\n",
    ")\n",
    "\n",
    "cur = cnx.cursor()\n",
    "cursor = cnx.cursor()\n",
    "ch_cur = cnx.cursor()\n",
    "\n",
    "# url = \"https://www.tripadvisor.com.tw/Restaurant_Review-g13806900-d4600419-Reviews-Sunny_Hills-Songshan_Taipei.html\"\n",
    "hr = \"SELECT near_href,near_site FROM comment_relationship\"\n",
    "cursor.execute(hr)\n",
    "\n",
    "rhref = []\n",
    "for j in cursor.fetchall():\n",
    "    # near\n",
    "    url = j[0]\n",
    "    check = url[31:41]\n",
    "    \n",
    "    if check == \"Restaurant\":\n",
    "        rhref.append(url)\n",
    "\n",
    "for row in rhref:\n",
    "    rest_check = \"SELECT id FROM resta_data WHERE href = '\" + row + \"'\"\n",
    "    ch_cur.execute(rest_check)\n",
    "    entry = ch_cur.fetchone()\n",
    "    if entry is None:\n",
    "        getResta(row)\n",
    "            \n",
    "tEnd = time.time()\n",
    "print(\"Run Time：\", tEnd - tStart)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
